{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, model_selection, metrics, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wine dataset and split\n",
    "wine = datasets.load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an estimator and predict using the fitted estimator\n",
    "estimator = tree.DecisionTreeClassifier(max_depth=3)\n",
    "estimator = estimator.fit(X_train, y_train)\n",
    "y_pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a confusion matirx using sklearn >= 0.22\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "cmd = metrics.ConfusionMatrixDisplay(cm, wine.target_names)\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    fmt=None,\n",
    "    normalize=False,\n",
    "    percentage=False,\n",
    "    label_names=None,\n",
    "    true_name='True label',\n",
    "    pred_name='Predicted label',\n",
    "    cmap='Reds',\n",
    "    show_accuracy=True,\n",
    "    accuracy_fmt='{:.2%}',\n",
    "):\n",
    "    labels = sorted(np.unique(np.concatenate([y_true, y_pred])))\n",
    "    if label_names is None:\n",
    "        label_names = labels\n",
    "    df = pd.DataFrame(metrics.confusion_matrix(y_true, y_pred, labels=labels))\n",
    "    df.index = pd.MultiIndex.from_product([[true_name], label_names])\n",
    "    df.columns = pd.MultiIndex.from_product([[pred_name], label_names])\n",
    "    if normalize:\n",
    "        df /= df.sum().sum()\n",
    "        if fmt is None:\n",
    "            fmt = '{:.6f}'\n",
    "    elif percentage:\n",
    "        df /= df.sum().sum()\n",
    "        if fmt is None:\n",
    "            fmt = '{:.2%}'\n",
    "    else:\n",
    "        if fmt is None:\n",
    "            fmt = '{:,}'\n",
    "    display(df.style.background_gradient(cmap=cmap, axis=None).format(fmt))\n",
    "    if show_accuracy:\n",
    "        print('accuracy = ' + accuracy_fmt.format(metrics.accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a confusion matrix\n",
    "display_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a confusion matrix with label names\n",
    "display_confusion_matrix(y_test, y_pred, label_names=wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a normalized confusion matrix\n",
    "display_confusion_matrix(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a normalized confusion matrix with percentage\n",
    "display_confusion_matrix(y_test, y_pred, percentage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a confusion matrix with the specified color map\n",
    "display_confusion_matrix(y_test, y_pred, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_importance(\n",
    "    feature_importances,\n",
    "    feature_names=None,\n",
    "    sort_descending=True,\n",
    "    ignore_zeros=False,\n",
    "    color='#d65f5f',\n",
    "):\n",
    "    df = pd.DataFrame({'importance': feature_importances})\n",
    "    if feature_names is not None:\n",
    "        df.index = feature_names\n",
    "    if ignore_zeros:\n",
    "        df = df.loc[df['importance'] > 0]\n",
    "    if sort_descending:\n",
    "        df = df.sort_values(by='importance', ascending=False)\n",
    "    display(df.style.bar(color=color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importances\n",
    "display_feature_importance(estimator.feature_importances_, wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display non-zero feature importances\n",
    "display_feature_importance(estimator.feature_importances_, wine.feature_names, ignore_zeros=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
